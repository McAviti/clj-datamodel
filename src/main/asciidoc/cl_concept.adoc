:hide-uri-scheme:

== An Architecture Blueprint for a Central Logging System

=== Introduction
Logging is mostly treated as a local affair: Of an application or solution, a team, or even a single developer, maybe
a group thereof. But the increasing complexity of software systems increases the effort to draw the
right conclusions from a large heap of heterogeneous logging records.

The trend from large monolithic application building blocks to smaller -- but therefore intensely interconnected --
software components is present. Therefore s IT Solutions AT (IT subsidiary of Erste Bank and Sparkassen in Austria,
https://www.s-itsolutions.at/) started a project to care for a central logging and journalling data lake. +
The architectural pattern here is a description along the line of this "Central Logging & Journalling"
solution/application of sIT. It is targeted not at smaller systems but tries to deal with enterprises and larger IT
landscapes.

So, if you feel your path to wisdom by reading logs looks like this, you're a happy developer already. +
image:forest_log.jpg[forest, role="thumb"]

But if it looks a bit more like this, further reading could maybe help you. +
image:jungle_log.JPG[jungle, role="thumb"]

=== Goals
Logging is not an end in itself -- it enables many use-cases that can be grouped into four partitions:

[A]. *Support:* Find out about what the system did in its runtime, in order to detect the source of problems or give
information to other stakeholders. Mostly use-cases here investigate in exceptional program behaviour.

[B]. *Compliance:* The number of regulatory use-cases increases; the run-time behaviour and intermediate data of
software must be documented, often for many years.

[C]. *Monitoring & Alerting:* When a stream of logging data exists, it is self-evident to use this stream also to find
out about the system state as well as problems and report those via multiple channels.

[D]. *Analytics & Intelligence:* Sophisticated tools allow data mining, BI etc. to find out ways to improve the
business, may it be by exploring customer behaviour, may it by predicting operations problems, or may it be something
we don't even dream of yet.

.Use-case groups
[options=header, frame=all, grid=cols, cols="<,<,<,<"]
|===
|Support [A] | Compliance [B] | Monitoring & Alerting [C] | Analytics & Intelligence [D]

|   * Customer Care +
    * Issue research +
    -> Access Security +
    -> Searchable, neartime
|    * Regulatory queries
     -> Long term +
     -> Safe data store +
     -> Ideally certified +
     -> Unfrequent queries
|   * Stream analysis +
    * Alerting endpoints +
    -> Needs rules +
    -> High performing
|   * Statistics +
    * Big Data Analysis +
    * Machine Learning +
    * Predictive Analysis +
    -> Highly specialized toolset
|===

=== Architecture

A possible architecture could make use of the following building blocks:

[[clj-architecture]]
.Logical architecture of CLJ
image::logical_arch.png[]

The functional as well as the non-functional, or quality, requirements of the use-case groups aforementioned are
very different from each other. Therefore it makes sense to use different software products to fulfill those
requirements.

==== Messaging Brick
This building block cares for a reliable (real 24/7) component where the applications can load their logging records
up to. It is high-performant, lean, stable and therefore capable to also swallow extreme high-load peaks.

This building block also cares for the use-case group [C]. The type of product is queue-like, our implementation uses
Apache Kafka (https://kafka.apache.org/). Another example would be to use Amazon's Firehose/Kinesis in an AWS-based
environment.

==== Online Research Store
This record store is responsible for the structured and fast search for log records and to find out about connections
between those.

Our implementation uses ElasticSearch (https://www.elastic.co/de/) together with a self-written ReST service and an
Angular-base front-end

==== Compliance Store
Selected log records (defined by the solution) are persisted in this record store. It is very reliable, needs a
back-up, is fast with writing and stores the record before any tampering with it. On the other hand it does not need
a super-sophisticated query facility.

In our implementation we decided for Apache Cassandra (http://cassandra.apache.org/).

==== The Client Side
The applications for logging can send their log records either directly into the messaging brick or by harvesting
them from the filesystem or another data store. Both methods have pro's and con's.

.Harvesting methods.
[options=header]
|===
| Direct transfer | Logfile harvesting

| + Fastest +
  + Possibly eliminates one component (file system)
  - Technically a tight coupling
| + Non-intrusive to existing applications +
  - Needs another process (ressources + monitoring)
|===

===== Direct transfer
Possibilities for applications to integrate are:

- Own client libs of messaging brick
- APIs for creating messages that fit to the data model of CLJ
- Appenders for existing logging frameworks (e.g. log4j2 in Java, or log.net for C#)

Generally it is a good idea to offer integration libraries that care for the situations where the messaging brick
suffers from a failure. In those cases the using application should not be brought down by logging, to mitigate
the tight coupling issue.

==== Logfile harvesting
There are a lot of tools for that use-case, ranging from light-weight native apps that are integrated into the
operating system up to full-scale ETL tools (https://en.wikipedia.org/wiki/Extract,_transform,_load).

A few examples:

- rsyslog (http://www.rsyslog.com/)
- fluentd (https://www.fluentd.org/)
- Apache flume (https://flume.apache.org/)
- ElasticSearch' beat-family (https://www.elastic.co/products/beats)
- logstash (https://www.elastic.co/products/logstash, the 'L' from the famous ELK stack)

In certain architectures, some of these products could server as the messaging brick itself.

